patch cm wmltrainingconfigmap -p '{"data": {"trainingService.conf": "akka {\n  loggers = [\"akka.event.Logging$DefaultLogger\"]\n  loglevel = \"WARNING\"\n  logging-filter = \"akka.event.slf4j.Slf4jLoggingFilter\"\n\n  http {\n    server {\n      max-connections = 1024\n      idle-timeout = 130s\n      request-timeout = 200s\n    }\n\n  }\n\n}\n\nservice {\n      rmq-icd=false\n      redis-icd=false\n      wml-training-data-pvc = \"wml-training-data\"\n\n      validateTokenService.ml.pubkey.path = \"/opt/ibm/training/keys/mltoken.pub\"\n      validateTokenService.icp.pubkey.path = \"/user-home/_global_/config/jwt/public.pem\"\n\n      enable-ssl = true\n      enable-queue = false\n      runtimes = [\"scala-spark-2.1\", \"scala-spark-2.3\"]\n      request.timeout.seconds = 115\n\n      threadpool.size = 150\n\n      http {\n        port = 13300\n      }\n\n      security {\n        key-store = \"/opt/ibm/training/keys/icpkeystore.jks\"\n        key-store-type = \"JKS\"\n      }\n\n\n      repository {\n        url = \"https://internal-nginx-svc:12443\"\n      }\n\n      cloudant {\n        db-name = \"d21sLXRyYWluaW5n\"\n        port = 6984\n        cleanup.interval.hours = 24\n        cleanup.older.days = 14\n        cleanup.delay.ms = 500\n      }\n\n      api-docs {\n        url = \"http://watson-ml-api.mybluemix.net/\"\n      }\n\n      wmla {\n        use_proxy = false\n        proxy_host = \"9.21.55.13\"\n        proxy_port = 30123\n        use_url_metrics=true\n      }\n\n      rabbitmq {\n        subscriber.timeout.seconds = 60\n        exchange = \"training-prod\"\n        queue_expiration_hours = 24\n        threadpool.size = 100\n      }\n\n\n\n      compute {\n        tshirt_sizes {\n          xs.cpu = \"1\"\n          xs.mem = \"4Gi\"\n\n          s.cpu = \"2\"\n          s.mem = \"8Gi\"\n\n          m.cpu = \"4\"\n          m.mem = \"16Gi\"\n\n          l.cpu = \"8\"\n          l.mem = \"32Gi\"\n\n          xl.cpu = \"16\"\n          xl.mem = \"64Gi\"\n        }\n      }\n\n      auto_ai.kb {\n        image = \"{{.DockerRegistryPrefix}}/wml-autoai-kb\"\n        default.version = \"v.0.2.296.0.23\"\n        port = 5449\n    }\n\n      kube-config {\n        encrypted-certificate-authority = \"/opt/ibm/wml-training/encrypted/ca.pem\"\n        encrypted-client-certificate = \"/opt/ibm/wml-training/encrypted/admin.pem\"\n        encrypted-client-key = \"/opt/ibm/wml-training/encrypted/admin-key.pem\"\n        yaml = \"/opt/ibm/wml-training/kube-config.yml\"\n      }\n\n      training-affinity = \"wml\"\n    }\n"},"name": "wmltrainingconfigmap"}'

patch cm wmlruntimemanager -p '{"data": { "ai-function-runtime-config-fvt.json": "{\n  \"ai-function\": {\n    \"deprecated_versions\": {\n      \"0.1.368\": {\n        \"reference\": \"Python function with python 3.6 is deprecated and will be removed in the future. Use Python function with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"0.1.368\": {\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py368-g1-rt:v.0.1.61.0.68\",\n      \"os_min_pods\": \"0\",\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py368-g1-rt:v.0.1.61.0.68\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"configvolumemap\": \"wmlscoringaifunc\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"0.1.379\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringaifunc\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n      \"ai-function_0.1\": {\n        \"ai-function_0.1-py3.6\": \"0.1.368\",\n        \"ai-function_0.2-py3.7\": \"0.1.379\"\n      }\n    },\n    \"policy\": {\n      \"cold\": {\n        \"lite\": {\n          \"retention_period\": \"0\"\n        },\n        \"standard\": {\n          \"retention_period\": \"0\"\n        },\n        \"professional\": {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\": {\n          \"retention_period\": \"0\"\n        }\n      }\n    }\n  },\n  \"status\": \"SUCCESS\",\n  \"os_default_size\": \"204800\"\n}", "name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": { "runtimeManager.conf": "akka {\n  loggers = [\"akka.event.slf4j.Slf4jLogger\"]\n  loglevel = \"INFO\"\n\n  log-dead-letters = 10\n  log-dead-letters-during-shutdown = on\n  # log-config-on-start = on\n  http.server.request-timeout = 120 s\n  http.server.idle-timeout = 121 s\n  http.server.parsing.max-content-length = 100m\n\n  actor {\n    default-dispatcher {\n      default-executor {\n        fallback: \"fork-join-executor\"\n      }\n      executor = \"fork-join-executor\"\n      fork-join-executor {\n        parallelism-min = 4\n        parallelism-factor = 64\n        parallelism-max = 128\n        throughput = 1\n      }\n    }\n  }\n\n  scoring-main-dispatcher {\n    type = \"Dispatcher\"\n    executor = \"fork-join-executor\"\n    fork-join-executor {\n      parallelism-min = 8\n      parallelism-factor = 64\n      parallelism-max = 128\n      throughput = 1\n    }\n  }\n\n  scoring-jobs-dispatcher {\n    type = \"Dispatcher\"\n    executor = \"fork-join-executor\"\n    fork-join-executor {\n      parallelism-min = 8\n      parallelism-factor = 64\n      parallelism-max = 128\n      throughput = 1\n    }\n  }\n\n  scoring-deployments-dispatcher {\n    type = \"Dispatcher\"\n    executor = \"fork-join-executor\"\n    fork-join-executor {\n      parallelism-min = 8\n      parallelism-factor = 64\n      parallelism-max = 128\n      throughput = 1\n    }\n  }\n\n  http.host-connection-pool {\n    # The maximum number of open requests accepted into the pool across all\n    # materializations of any of its client flows.\n    # Protects against (accidentally) overloading a single pool with too many client flow materializations.\n    # Note that with N concurrent materializations the max number of open request in the pool\n    # will never exceed N * max-connections * pipelining-limit.\n    # Must be a power of 2 and > 0!\n    max-open-requests = 256\n    max-connections = 64\n  }\n}\n\nservice {\n\n  # Runtime configuration and runtime deployment template\n  runtime_config = \"/opt/ibm/wml-online-scoring/runtime-manager/conf\"\n  runtime_template = \"/opt/ibm/wml-online-scoring/runtime-manager/conf/deployment-fvt.yaml\"\n  runtime_environment = \"fvt\"\n  kube_cluster_timeout = 120\n  kube_cluster_creation_timeout = 600\n\n  # Config for Validate Token connection\n  validateTokenService {\n    // public key may be provided via file or url\n    ml.pubkey.path = \"/opt/ibm/wml-online-scoring/runtime-manager/keys/mltoken.pub\"\n    icp.pubkey.path = \"/user-home/_global_/config/jwt/public.pem\"\n  }\n\n  ml_repository {\n    url = \"https://internal-nginx-svc:12443\"\n    spacesGetLimit = 50\n  }\n\n  wmlService {\n    url = \"https://internal-nginx-svc:12443\"\n    timeout = 60\n    icpport = \"31843\"\n  }\n\n  envoy {\n    url = \"https://wml-os-envoy:32006\"\n  }\n\n  replication.factor = 2\n  //  http.service.interface = \"localhost\"\n  http.service.port = 16500\n\n  enable-ssl = true\n\n  ssl {\n    port = 16500\n    keystore {\n      path = \"/opt/ibm/wml-online-scoring/runtime-manager/keys/private/keystore.jks\"\n      type = \"JKS\"\n    }\n  }\n\n  runtime_manager {\n    deployment {\n      lock_delay = 15 //Minutes\n    }\n  }\n\n  resiliency {\n    delay = 500   // In millisecodns\n    retries = 3\n  }\n\n  iam {\n    url = \"dummy\"\n    pdp {\n      serviceName = \"pm-20-dev\"\n      apiKey = \"\"\n    }\n  }\n\n  kube-config {\n    job.activeDeadlineSeconds = 900\n  }\n\n  wml_instances {\n    url = \"https://wml-fvt.ml.test.cloud.ibm.com/v3/wml_instances\"\n  }\n\n  features {\n    list = [\"SPACES\"]\n  }\n\n  space_access {\n    post = [\"Admin\", \"Editor\"]\n    get = [\"Admin\", \"Editor\", \"Viewer\"]\n    patch = [\"Admin\", \"Editor\"]\n    delete = [\"Admin\", \"Editor\"]\n\n  }\n\n  ml-event-client {\n    topicSpace = \"misc\"\n    messageProcessParallelism = 20\n    v4TopicSpace = \"deployments\"\n  }\n\n  batchapp.jar {\n    name2_3 = \"/opt/ibm/third-party/libs/batch/wml-online-scoring-runner-hummingbird.jar\"\n    mainclass = \"com.ibm.analytics.wml.batch_deploy.runner.application.BatchApp\"\n  }\n\n  hummingbird {\n    url_base = \"https://internal-nginx-svc:12443/ae/\"\n    url_suffix = \"/v2/jobs\"\n  }\n\n  rolling-update {\n    maxThreadsRollingUpdate = 10\n    maxWaitSingleTenant = 1000\n    maxWaitMultiTenant = 2000\n  }\n\n  async_persistant_storage.base_dir = \"/manager-pvc\"\n\n  virtual_deployment {\n    images {\n      scikit_learn_0_20 = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\"\n      xgboost_0_82 = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\"\n      scikit_learn_0_23 = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\"  \n      xgboost_0_90 = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\"  \n    }\n  }\n\n  rabbitmq {\n    subscriber.timeout.seconds = 10\n    exchange = \"scoring-fvt\"\n    queue_expiration_hours = 24\n    threadpool.size = 50\n    queues = [\"non-do-job-queue\", \"do-job-queue\"]\n    do_queue_name = \"do-job-queue\"\n    non_do_queue_name = \"non-do-job-queue\"\n    routing_keys = [\"non_do_routing_key\", \"do_routing_key\"]\n    do_queue_routing_key = \"do_routing_key\"\n    non_do_queue_routing_key = \"non_do_routing_key\"\n  }\n\n  jobs_thread {\n    post_factor = 50\n  }\n\n  aios {\n      skip_list = []\n  }\n\n  pod_spawn {\n    memory_factor = 0.7\n    deploy_by_number = true\n  }\n\n  etcd_fetch_limit = 1200\n  one_node {\n    pod_cleanup {\n      delay_interval = 900\n      interval = 1200\n    }\n  }\n\n  autoai {\n    kb {\n      image_tag = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-autoai_kb_3.0-py3612-g1-rt:v.0.1.61.0.84\"\n      version_prefix = [\"v.0.1.296\"]\n    }\n    kbpy37 {\n      image_tag = \"{{.DockerRegistryPrefix}}/wml-ubi-x86-autoai_kb_3.1-py379-g1-rt:v.0.1.61.0.65\"\n    }\n  }\n}\n\ngrpc {\n  service {\n    agent_interface = \"wml-scoring-rt-utils\"\n    agent_port = 16502\n  }\n}\n", "name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"caffe-runtime-config-fvt.json": "{\n  \"caffe\": {\n    \"deprecated_versions\": {\n      \"1.0\": {\n        \"reference\": \"Caffe 1.0 framework for Watson Machine Learning is deprecated and will be removed in the future. Use other supported frameworks instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"1.0\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringcaffe10\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n      \"caffe_1.0\": {\n        \"caffe_1.0-py3\": \"1.0\"\n      }\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n      }\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"83886080\"\n}", "name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": { "do-runtime-config-fvt.json": "{\n  \"do\": {\n    \"12.9\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-do12.9:v.1.0-cp4d-v2.5-b15\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-do12.9:v.1.0-cp4d-v2.5-b15\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/do/conf\",\n      \"configvolumemap\": \"wmlscoringdo\"\n    },        \n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    }\n  },\n  \"status\": \"NORMAL\",\n  \"os_default_size\": \"0\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"hybrid-runtime-config-fvt.json": "{\n  \"hybrid\": {\n     \"deprecated_versions\": {\n       \"0.1\": {\n      \"reference\": \"AutoAI models trained in Cloud Pak for Data prior to the 2.5 Patch-2 release are built on a deprecated framework and will be unsupported in the future. After Patch-2 is applied, retrain, then redeploy your AutoAI models. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html.\"\n  }\n },\n    \"0.1\": {\n      \"current_version\":  \"{{.DockerRegistryPrefix}}/wml-os-runtimes-hybrid:v.0.1.248.0.6\",\n      \"next_version\":  \"{{.DockerRegistryPrefix}}/wml-os-runtimes-hybrid:v.0.1.248.0.6\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/hybrid/conf\",\n      \"configvolumemap\": \"wmlscoringmllib\"\n    },\n    \"0.2\": {\n      \"current_version\":  \"{{.DockerRegistryPrefix}}/wml-os-runtimes-hybrid:v.0.1.248.0.6\",\n      \"next_version\":  \"{{.DockerRegistryPrefix}}/wml-os-runtimes-hybrid:v.0.1.248.0.6\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/hybrid/conf\",\n      \"configvolumemap\": \"wmlscoringmllib\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    },\n    \"runtime_mapping\": {\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"83886080\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": { "keras-runtime-config-fvt.json": "{\n  \"keras\": {\n    \"deprecated_versions\": {\n      \"2.2.4-tf\": {\n        \"reference\": \"Keras 2.2.4-tf framework for Watson Machine Learning is deprecated and will be removed in the future. Use tf.keras APIs in Tensorflow 2.1 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      },\n      \"2.1.6\": {\n        \"reference\": \"Keras 2.1.6 framework for Watson Machine Learning is deprecated and will be removed in the future. Use tf.keras APIs in Tensorflow 2.1 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      },\n      \"2.2.4\": {\n        \"reference\": \"Keras 2.2.4 framework for Watson Machine Learning is deprecated and will be removed in the future. Use tf.keras APIs in Tensorflow 2.1 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"2.2.4-tf\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf113\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"2.1.6\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf113\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"2.2.4\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf114\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n      \"keras_2.1.6\": {\n        \"tensorflow_1.13-py3\": \"2.1.6\",\n        \"tensorflow_1.13-py3.6\": \"2.1.6\"\n      },\n      \"keras_2.2.4-tf\": {\n        \"tensorflow_1.13-py3\": \"2.2.4-tf\",\n        \"tensorflow_1.13-py3.6\": \"2.2.4-tf\"\n      },\n      \"keras_2.2.4\": {\n        \"tensorflow_1.14-py3\": \"2.2.4\",\n        \"tensorflow_1.14-py3.6\": \"2.2.4\"\n      }\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"83886080\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"mllib-runtime-config-fvt.json": "{\n  \"mllib\": {\n    \"deprecated_versions\": {\n       \"2.2\": {\n      \"reference\": \"Spark 2.2 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Spark 2.4 with V4 WML APIs instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html.\" },\n         \"2.3\": {\n      \"reference\": \"Spark 2.3 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Spark 2.4 with V4 WML APIs instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html.\" }\n  },\n     \"2.2\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n      \"configvolumemap\": \"wmlscoringmllib\"\n    },\n    \"2.4\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.4:v.0.1.501.0.11\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.4:v.0.1.501.0.11\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n      \"configvolumemap\": \"wmlscoringmllib\"\n    },\n    \"2.3\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.3:v.0.1.501.0.11\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.3:v.0.1.501.0.11\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n      \"configvolumemap\": \"wmlscoringmllib\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n    },\n    \"policy\": {\n      \"cold\": {\n        \"lite\": {\n          \"retention_period\": \"0\"\n        },\n        \"standard\": {\n          \"retention_period\": \"0\"\n        },\n        \"professional\": {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\": {\n          \"retention_period\": \"0\"\n        }\n      }\n    }\n  },\n  \"status\": \"NORMAL\",\n  \"os_default_size\": \"204800\"\n}\n","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"pytorch-onnx-runtime-config-fvt.json": "{\n  \"pytorch-onnx\": {\n    \"deprecated_versions\": {\n      \"1.0\": {\n        \"reference\": \"Pytorch 1.0 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Pytorch 1.3 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      },\n      \"1.1\": {\n        \"reference\": \"Pytorch 1.1 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Pytorch 1.3 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"1.0\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringpytorchonnx10\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"1.1\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringpytorchonnx11\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"1.3\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringpytorchonnx13-250\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"size\": {\n      \"xsmall\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    },\n    \"runtime_mapping\": {\n      \"pytorch-onnx_1.0\": {\n        \"pytorch-onnx_1.0-py3\": \"1.0\",\n        \"pytorch-onnx_1.0-py3.6\": \"1.0\",\n        \"pytorch_1.0-py3\": \"1.0\",\n        \"pytorch_1.0-py3-edt\": \"1.0\"\n      },\n      \"pytorch-onnx_1.1\": {\n          \"pytorch-onnx_1.1-py3.6\": \"1.1\",\n          \"pytorch-onnx_1.1-py3.6-edt\": \"1.1\"\n      },\n      \"pytorch-onnx_1.3\": {\n          \"pytorch-onnx_1.3-py3.7\": \"1.3\",\n          \"pytorch-onnx_1.3-py3.7-edt\": \"1.3\"\n      }\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"83886080\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"scikit-runtime-config-fvt.json": "{\n    \"scikit-learn\": {\n      \"deprecated_versions\": {\n        \"0.20\": {\n          \"reference\": \"Scikit-learn 0.20/XGBoost 0.82 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Scikit-learn 0.23/XGBoost 0.90 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n        }\n      },\n      \"0.20\": {\n        \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n        \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n        \"os_min_pods\": \"0\",\n        \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n        \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n        \"configvolumemap\": \"wmlscoringsklearn20\",\n        \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n      },\n      \"0.23\": {\n        \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n        \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n        \"os_min_pods\": \"0\",\n        \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n        \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n        \"configvolumemap\": \"wmlscoringsklearn23-250\",\n        \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n      },\n      \"size\": {\n        \"xsmall\": {\n          \"memory\": \"2Gi\",\n          \"cpu\": \"2\"\n        },\n        \"small\": {\n          \"memory\": \"2Gi\",\n          \"cpu\": \"2\"\n        },\n        \"medium\": {\n          \"memory\": \"4Gi\",\n          \"cpu\": \"2\"\n        },\n        \"large\": {\n          \"memory\": \"6Gi\",\n          \"cpu\": \"2\"\n        },\n        \"xlarge\": {\n          \"memory\": \"8Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_small\": {\n          \"memory\": \"2Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_medium\": {\n          \"memory\": \"4Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_large\": {\n          \"memory\": \"6Gi\",\n          \"cpu\": \"2\"\n        }\n      },\n      \"runtime_mapping\": {\n        \"scikit-learn_0.20\": {\n          \"scikit-learn_0.20-py3\": \"0.20\",\n          \"scikit-learn_0.20-py3.6\": \"0.20\",\n          \"xgboost_0.82-py3\": \"0.20\",\n          \"xgboost_0.82-py3.6\": \"0.20\"\n        },\n        \"xgboost_0.82\": {\n          \"xgboost_0.82-py3\": \"0.20\",\n          \"xgboost_0.82-py3.6\": \"0.20\"\n        },\n        \"scikit-learn_0.23\": {\n          \"scikit-learn_0.23-py3.7\": \"0.23\"\n        },\n        \"xgboost_0.90\": {\n          \"scikit-learn_0.23-py3.7\": \"0.23\"\n        }\n      },\n      \"policy\": {\n        \"cold\":\n        {\n          \"lite\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"standard\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"professional\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"enterprise\":\n          {\n            \"retention_period\": \"0\"\n          }\n\n        }\n      }\n    },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"204800\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"spss-modeler-runtime-config-fvt.json": "{\n  \"spss-modeler\": {\n    \"18.1\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-spss18.1:v.0.1.445.0.8\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-spss18.1:v.0.1.445.0.8\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/mlonlinespss/conf\",\n      \"configvolumemap\": \"wmlscoringspss\"\n    },\n    \"17.1\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-spss18.1:v.0.1.445.0.8\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-spss18.1:v.0.1.445.0.8\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/mlonlinespss/conf\",\n      \"configvolumemap\": \"wmlscoringspss\"\n    },\n    \"batch\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-batch-runtimes-spss18.1:v.0.1.445.0.8\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-batch-runtimes-spss18.1:v.0.1.445.0.8\",\n       \"configvolume\":\"/opt/ibm/mlonlinespss/conf\",\n       \"os_min_pods\":\"0\",\n        \"configvolumemap\":\"wmlscoringspss\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    }\n  },\n  \"status\": \"NORMAL\",\n  \"os_default_size\": \"0\"\n}\n","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"tensorflow-runtime-config-fvt.json": "{\n  \"tensorflow\": {\n    \"deprecated_versions\": {\n      \"1.14\": {\n        \"reference\": \"Tensorflow 1.14 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Tensorflow 2.1 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      },\n      \"1.13\": {\n        \"reference\": \"Tensorflow 1.13 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Tensorflow 2.1 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"2.1\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf21-250\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"1.14\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g2-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf114\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"1.13\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringtf113\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"size\": {\n      \"xsmall\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n        \"tensorflow_1.13\": {\n          \"tensorflow_1.13-py3\": \"1.13\",\n          \"tensorflow_1.13-py3.6\": \"1.13\"\n        },\n        \"tensorflow_1.14\": {\n          \"tensorflow_1.14-py3\": \"1.14\",\n          \"tensorflow_1.14-py3.6\": \"1.14\"\n        },\n        \"tensorflow_2.1\": {\n          \"tensorflow_2.1-py3.7\": \"2.1\"\n        }\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"83886080\"\n}","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"wml-runtime-config-fvt.json": "{\n    \"wml\": {\n      \"1.6\": {\n        \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"os_min_pods\": \"0\",\n        \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n        \"configvolumemap\": \"wmlscoringmllib\"\n      },\n      \"2.0\": {\n        \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"os_min_pods\": \"0\",\n        \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n        \"configvolumemap\": \"wmlscoringmllib\"\n      },\n      \"2.1\": {\n        \"current_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"next_version\": \"{{.DockerRegistryPrefix}}/wml-os-runtimes-mllib2.2:v.0.1.501.0.11\",\n        \"os_min_pods\": \"0\",\n        \"configvolume\": \"/opt/ibm/wml-online-scoring/runtimes/spark-2.1/conf\",\n        \"configvolumemap\": \"wmlscoringmllib\"\n      },\n      \"size\": {\n        \"small\": {\n          \"memory\": \"2Gi\",\n          \"cpu\": \"2\"\n        },\n        \"medium\": {\n          \"memory\": \"4Gi\",\n          \"cpu\": \"2\"\n        },\n        \"large\": {\n          \"memory\": \"6Gi\",\n          \"cpu\": \"2\"\n        },\n        \"xlarge\": {\n          \"memory\": \"8Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_small\": {\n          \"memory\": \"2Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_medium\": {\n          \"memory\": \"4Gi\",\n          \"cpu\": \"2\"\n        },\n        \"batch_large\": {\n          \"memory\": \"6Gi\",\n          \"cpu\": \"2\"\n        }\n      },\n      \"runtime_mapping\": {\n      },\n      \"policy\": {\n        \"cold\":\n        {\n          \"lite\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"standard\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"professional\":\n          {\n            \"retention_period\": \"0\"\n          },\n          \"enterprise\":\n          {\n            \"retention_period\": \"0\"\n          }\n\n        }\n      }\n    },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"0\"\n}\n","name":"wmlruntimemanager"}}'

patch cm wmlruntimemanager -p '{"data": {"xgboost-runtime-config-fvt.json": "{\n  \"xgboost\": {\n    \"deprecated_versions\": {\n      \"0.82\": {\n        \"reference\": \"Scikit-learn 0.20/XGBoost 0.82 framework for Watson Machine Learning is deprecated and will be removed in the future. Use Scikit-learn 0.23/XGBoost 0.90 with python 3.7 instead. For details, see https://www.ibm.com/support/knowledgecenter/SSQNUZ_2.5.0/wsj/analyze-data/pm_service_supported_frameworks.html\"\n      }\n    },\n    \"0.82\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-ac201903-py368-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringsklearn20\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\"\n    },\n    \"0.90\": {\n      \"current_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"next_version\": \"{{.DockerRegistryPrefix}}/wml-ubi-x86-mc3-py379-g1-rt:v.0.1.61.0.83\",\n      \"os_min_pods\": \"0\",\n      \"configvolume\": \"/opt/ibm/scoring/python/conf-rt\",\n      \"pythoncommon\": \"/opt/ibm/scoring/python/conf-common\",\n      \"configvolumemap\": \"wmlscoringsklearn23-250\",\n      \"pythoncommonmap\": \"wmlscoringpythoncommon\",\n      \"keystore\": \"/opt/ibm/scoring/keys/private_ssl\",\n      \"keystoremap\": \"wmlsslcertsconfigmap\"\n    },\n    \"size\": {\n      \"small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      },\n      \"xlarge\": {\n        \"memory\": \"8Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_small\": {\n        \"memory\": \"2Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_medium\": {\n        \"memory\": \"4Gi\",\n        \"cpu\": \"2\"\n      },\n      \"batch_large\": {\n        \"memory\": \"6Gi\",\n        \"cpu\": \"2\"\n      }\n    },\n    \"runtime_mapping\": {\n    },\n    \"policy\": {\n      \"cold\":\n      {\n        \"lite\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"standard\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"professional\":\n        {\n          \"retention_period\": \"0\"\n        },\n        \"enterprise\":\n        {\n          \"retention_period\": \"0\"\n        }\n\n      }\n    }\n  },\n  \"status\":\"NORMAL\",\n  \"os_default_size\": \"0\"\n}","name":"wmlruntimemanager"}}'


create cm wmlscoringsklearn23-250 --from-literal module=wmldeployment
patch cm wmlscoringsklearn23-250 -p '{"data": { "newrelic.ini" : "# ---------------------------------------------------------------------------\n\n#\n# This file configures the New Relic Python Agent.\n#\n# The path to the configuration file should be supplied to the function\n# newrelic.agent.initialize() when the agent is being initialized.\n#\n# The configuration file follows a structure similar to what you would\n# find for Microsoft Windows INI files. For further information on the\n# configuration file format see the Python ConfigParser documentation at:\n#\n#    http://docs.python.org/library/configparser.html\n#\n# For further discussion on the behaviour of the Python agent that can\n# be configured via this configuration file see:\n#\n#    http://newrelic.com/docs/python/python-agent-configuration\n#\n\n# ---------------------------------------------------------------------------\n\n# Here are the settings that are common to all environments.\n\n[newrelic]\n\n# You must specify the license key associated with your New\n# Relic account. This key binds the Python Agents data to your\n# account in the New Relic service.\nlicense_key = 78ab31635abad63c0ad9eb0f409ed909e642d66c\n\n# The application name. Set this to be the name of your\n# application as you would like it to show up in New Relic UI.\n# The UI will then auto-map instances of your application into a\n# entry on your home dashboard page.\napp_name = wml-os-rt-scikit-learn0.23-fvt\n\n# When \"true\", the agent collects performance data about your\n# application and reports this data to the New Relic UI at\n# newrelic.com. This global switch is normally overridden for\n# each environment below.\nmonitor_mode = true\n\n# Sets the name of a file to log agent messages to. Useful for\n# debugging any issues with the agent. This is not set by\n# default as it is not known in advance what user your web\n# application processes will run as and where they have\n# permission to write to. Whatever you set this to you must\n# ensure that the permissions for the containing directory and\n# the file itself are correct, and that the user that your web\n# application runs as can write to the file. If not able to\n# write out a log file, it is also possible to say \"stderr\" and\n# output to standard error output. This would normally result in\n# output appearing in your web server log.\n#log_file = /tmp/newrelic-python-agent.log\n\n# Sets the level of detail of messages sent to the log file, if\n# a log file location has been provided. Possible values, in\n# increasing order of detail, are: \"critical\", \"error\", \"warning\",\n# \"info\" and \"debug\". When reporting any agent issues to New\n# Relic technical support, the most useful setting for the\n# support engineers is \"debug\". However, this can generate a lot\n# of information very quickly, so it is best not to keep the\n# agent at this level for longer than it takes to reproduce the\n# problem you are experiencing.\nlog_level = info\n\n# High Security Mode enforces certain security settings, and prevents\n# them from being overridden, so that no sensitive data is sent to New\n# Relic. Enabling High Security Mode means that request parameters are\n# not collected and SQL can not be sent to New Relic in its raw form.\n# To activate High Security Mode, it must be set to true in this\n# local .ini configuration file AND be set to true in the\n# server-side configuration in the New Relic user interface. For\n# details, see\n# https://docs.newrelic.com/docs/subscriptions/high-security\nhigh_security = false\n\n# The Python Agent will attempt to connect directly to the New\n# Relic service. If there is an intermediate firewall between\n# your host and the New Relic service that requires you to use a\n# HTTP proxy, then you should set both the \"proxy_host\" and\n# \"proxy_port\" settings to the required values for the HTTP\n# proxy. The \"proxy_user\" and \"proxy_pass\" settings should\n# additionally be set if proxy authentication is implemented by\n# the HTTP proxy. The \"proxy_scheme\" setting dictates what\n# protocol scheme is used in talking to the HTTP proxy. This\n# would normally always be set as \"http\" which will result in the\n# agent then using a SSL tunnel through the HTTP proxy for end to\n# end encryption.\n# proxy_scheme = http\n# proxy_host = hostname\n# proxy_port = 8080\n# proxy_user =\n# proxy_pass =\n\n# Capturing request parameters is off by default. To enable the\n# capturing of request parameters, first ensure that the setting\n# \"attributes.enabled\" is set to \"true\" (the default value), and\n# then add \"request.parameters.*\" to the \"attributes.include\"\n# setting. For details about attributes configuration, please\n# consult the documentation.\n# attributes.include = request.parameters.*\n\n# The transaction tracer captures deep information about slow\n# transactions and sends this to the UI on a periodic basis. The\n# transaction tracer is enabled by default. Set this to \"false\"\n# to turn it off.\ntransaction_tracer.enabled = true\n\n# Threshold in seconds for when to collect a transaction trace.\n# When the response time of a controller action exceeds this\n# threshold, a transaction trace will be recorded and sent to\n# the UI. Valid values are any positive float value, or (default)\n# \"apdex_f\", which will use the threshold for a dissatisfying\n# Apdex controller action - four times the Apdex T value.\ntransaction_tracer.transaction_threshold = apdex_f\n\n# When the transaction tracer is on, SQL statements can\n# optionally be recorded. The recorder has three modes, \"off\"\n# which sends no SQL, \"raw\" which sends the SQL statement in its\n# original form, and \"obfuscated\", which strips out numeric and\n# string literals.\ntransaction_tracer.record_sql = obfuscated\n\n# Threshold in seconds for when to collect stack trace for a SQL\n# call. In other words, when SQL statements exceed this\n# threshold, then capture and send to the UI the current stack\n# trace. This is helpful for pinpointing where long SQL calls\n# originate from in an application.\ntransaction_tracer.stack_trace_threshold = 0.5\n\n# Determines whether the agent will capture query plans for slow\n# SQL queries. Only supported in MySQL and PostgreSQL. Set this\n# to \"false\" to turn it off.\ntransaction_tracer.explain_enabled = true\n\n# Threshold for query execution time below which query plans\n# will not not be captured. Relevant only when \"explain_enabled\"\n# is true.\ntransaction_tracer.explain_threshold = 0.5\n\n# Space separated list of function or method names in form\n# module:function or module:class.function for which\n# additional function timing instrumentation will be added.\ntransaction_tracer.function_trace =\n\n# The error collector captures information about uncaught\n# exceptions or logged exceptions and sends them to UI for\n# viewing. The error collector is enabled by default. Set this\n# to \"false\" to turn it off.\nerror_collector.enabled = true\n\n# To stop specific errors from reporting to the UI, set this to\n# a space separated list of the Python exception type names to\n# ignore. The exception name should be of the form module:class.\nerror_collector.ignore_errors =\n\n# Browser monitoring is the Real User Monitoring feature of the UI.\n# For those Python web frameworks that are supported, this\n# setting enables the auto-insertion of the browser monitoring\n# JavaScript fragments.\nbrowser_monitoring.auto_instrument = true\n\n# A thread profiling session can be scheduled via the UI when\n# this option is enabled. The thread profiler will periodically\n# capture a snapshot of the call stack for each active thread in\n# the application to construct a statistically representative\n# call tree.\nthread_profiler.enabled = true\n\n# Your application deployments can be recorded through the\n# New Relic REST API. To use this feature provide your API key\n# below then use the `newrelic-admin record-deploy` command.\n# api_key =\n\n# ---------------------------------------------------------------------------\n\n#\n# The application environments. These are specific settings which\n# override the common environment settings. The settings related to a\n# specific environment will be used when the environment argument to the\n# newrelic.agent.initialize() function has been defined to be either\n# \"development\", \"test\", \"staging\" or \"production\".\n#\n\n[newrelic:development]\nmonitor_mode = false\n\n[newrelic:test]\nmonitor_mode = false\n\n[newrelic:staging]\napp_name = Python Application Staging\nmonitor_mode = true\n\n[newrelic:production]\nmonitor_mode = true\n\n# ---------------------------------------------------------------------------\n", "name":"wmlscoringsklearn23-250"}}'
patch cm wmlscoringsklearn23-250 -p '{"data": { "py_ml_scoring_container_configs.yml" : "flask_server_container_config:\n  app_ser_size: 1024\n\nscoring_container_config:\n  runtimes:\n    scikit-learn: [\"0.23\"]\n    xgboost: [\"0.90\"]\n  threshold_memory: 80\n  py_container_type: \"py_ml_container\"\n", "name":"wmlscoringsklearn23-250"}}'


create cm wmlscoringpytorchonnx13-250 --from-literal module=wmldeployment
patch cm wmlscoringpytorchonnx13-250 -p '{"data": { "newrelic.ini" : "# ---------------------------------------------------------------------------\n\n#\n# This file configures the New Relic Python Agent.\n#\n# The path to the configuration file should be supplied to the function\n# newrelic.agent.initialize() when the agent is being initialized.\n#\n# The configuration file follows a structure similar to what you would\n# find for Microsoft Windows INI files. For further information on the\n# configuration file format see the Python ConfigParser documentation at:\n#\n#    http://docs.python.org/library/configparser.html\n#\n# For further discussion on the behaviour of the Python agent that can\n# be configured via this configuration file see:\n#\n#    http://newrelic.com/docs/python/python-agent-configuration\n#\n\n# ---------------------------------------------------------------------------\n\n# Here are the settings that are common to all environments.\n\n[newrelic]\n\n# You must specify the license key associated with your New\n# Relic account. This key binds the Python Agents data to your\n# account in the New Relic service.\nlicense_key = 78ab31635abad63c0ad9eb0f409ed909e642d66c\n\n# The application name. Set this to be the name of your\n# application as you would like it to show up in New Relic UI.\n# The UI will then auto-map instances of your application into a\n# entry on your home dashboard page.\napp_name = wml-os-rt-pytorch-onnx13-fvt\n\n\n# When \"true\", the agent collects performance data about your\n# application and reports this data to the New Relic UI at\n# newrelic.com. This global switch is normally overridden for\n# each environment below.\nmonitor_mode = true\n\n# Sets the name of a file to log agent messages to. Useful for\n# debugging any issues with the agent. This is not set by\n# default as it is not known in advance what user your web\n# application processes will run as and where they have\n# permission to write to. Whatever you set this to you must\n# ensure that the permissions for the containing directory and\n# the file itself are correct, and that the user that your web\n# application runs as can write to the file. If not able to\n# write out a log file, it is also possible to say \"stderr\" and\n# output to standard error output. This would normally result in\n# output appearing in your web server log.\n#log_file = /tmp/newrelic-python-agent.log\n\n# Sets the level of detail of messages sent to the log file, if\n# a log file location has been provided. Possible values, in\n# increasing order of detail, are: \"critical\", \"error\", \"warning\",\n# \"info\" and \"debug\". When reporting any agent issues to New\n# Relic technical support, the most useful setting for the\n# support engineers is \"debug\". However, this can generate a lot\n# of information very quickly, so it is best not to keep the\n# agent at this level for longer than it takes to reproduce the\n# problem you are experiencing.\nlog_level = info\n\n# High Security Mode enforces certain security settings, and prevents\n# them from being overridden, so that no sensitive data is sent to New\n# Relic. Enabling High Security Mode means that request parameters are\n# not collected and SQL can not be sent to New Relic in its raw form.\n# To activate High Security Mode, it must be set to true in this\n# local .ini configuration file AND be set to true in the\n# server-side configuration in the New Relic user interface. For\n# details, see\n# https://docs.newrelic.com/docs/subscriptions/high-security\nhigh_security = false\n\n# The Python Agent will attempt to connect directly to the New\n# Relic service. If there is an intermediate firewall between\n# your host and the New Relic service that requires you to use a\n# HTTP proxy, then you should set both the \"proxy_host\" and\n# \"proxy_port\" settings to the required values for the HTTP\n# proxy. The \"proxy_user\" and \"proxy_pass\" settings should\n# additionally be set if proxy authentication is implemented by\n# the HTTP proxy. The \"proxy_scheme\" setting dictates what\n# protocol scheme is used in talking to the HTTP proxy. This\n# would normally always be set as \"http\" which will result in the\n# agent then using a SSL tunnel through the HTTP proxy for end to\n# end encryption.\n# proxy_scheme = http\n# proxy_host = hostname\n# proxy_port = 8080\n# proxy_user =\n# proxy_pass =\n\n# Capturing request parameters is off by default. To enable the\n# capturing of request parameters, first ensure that the setting\n# \"attributes.enabled\" is set to \"true\" (the default value), and\n# then add \"request.parameters.*\" to the \"attributes.include\"\n# setting. For details about attributes configuration, please\n# consult the documentation.\n# attributes.include = request.parameters.*\n\n# The transaction tracer captures deep information about slow\n# transactions and sends this to the UI on a periodic basis. The\n# transaction tracer is enabled by default. Set this to \"false\"\n# to turn it off.\ntransaction_tracer.enabled = true\n\n# Threshold in seconds for when to collect a transaction trace.\n# When the response time of a controller action exceeds this\n# threshold, a transaction trace will be recorded and sent to\n# the UI. Valid values are any positive float value, or (default)\n# \"apdex_f\", which will use the threshold for a dissatisfying\n# Apdex controller action - four times the Apdex T value.\ntransaction_tracer.transaction_threshold = apdex_f\n\n# When the transaction tracer is on, SQL statements can\n# optionally be recorded. The recorder has three modes, \"off\"\n# which sends no SQL, \"raw\" which sends the SQL statement in its\n# original form, and \"obfuscated\", which strips out numeric and\n# string literals.\ntransaction_tracer.record_sql = obfuscated\n\n# Threshold in seconds for when to collect stack trace for a SQL\n# call. In other words, when SQL statements exceed this\n# threshold, then capture and send to the UI the current stack\n# trace. This is helpful for pinpointing where long SQL calls\n# originate from in an application.\ntransaction_tracer.stack_trace_threshold = 0.5\n\n# Determines whether the agent will capture query plans for slow\n# SQL queries. Only supported in MySQL and PostgreSQL. Set this\n# to \"false\" to turn it off.\ntransaction_tracer.explain_enabled = true\n\n# Threshold for query execution time below which query plans\n# will not not be captured. Relevant only when \"explain_enabled\"\n# is true.\ntransaction_tracer.explain_threshold = 0.5\n\n# Space separated list of function or method names in form\n# module:function or module:class.function for which\n# additional function timing instrumentation will be added.\n# transaction_tracer.function_trace =\n\n# The error collector captures information about uncaught\n# exceptions or logged exceptions and sends them to UI for\n# viewing. The error collector is enabled by default. Set this\n# to \"false\" to turn it off.\nerror_collector.enabled = true\n\n# To stop specific errors from reporting to the UI, set this to\n# a space separated list of the Python exception type names to\n# ignore. The exception name should be of the form module:class.\n# error_collector.ignore_errors =\n\n# Browser monitoring is the Real User Monitoring feature of the UI.\n# For those Python web frameworks that are supported, this\n# setting enables the auto-insertion of the browser monitoring\n# JavaScript fragments.\nbrowser_monitoring.auto_instrument = true\n\n# A thread profiling session can be scheduled via the UI when\n# this option is enabled. The thread profiler will periodically\n# capture a snapshot of the call stack for each active thread in\n# the application to construct a statistically representative\n# call tree.\nthread_profiler.enabled = true\n\n# Your application deployments can be recorded through the\n# New Relic REST API. To use this feature provide your API key\n# below then use the `newrelic-admin record-deploy` command.\n# api_key =\n\n# ---------------------------------------------------------------------------\n\n#\n# The application environments. These are specific settings which\n# override the common environment settings. The settings related to a\n# specific environment will be used when the environment argument to the\n# newrelic.agent.initialize() function has been defined to be either\n# \"development\", \"test\", \"staging\" or \"production\".\n#\n\n[newrelic:development]\nmonitor_mode = false\n\n[newrelic:test]\nmonitor_mode = false\n\n[newrelic:staging]\napp_name = Python Application (Staging)\nmonitor_mode = true\n\n[newrelic:production]\nmonitor_mode = true\n\n# ---------------------------------------------------------------------------\n", "name":"wmlscoringpytorchonnx13-250"}}'
patch cm wmlscoringpytorchonnx13-250 -p '{"data": { "py_ml_scoring_container_configs.yml" : "flask_server_container_config:\n  app_ser_size: 1024\n\nscoring_container_config:\n  runtimes:\n    pytorch-onnx: [\"1.3\"]\n  threshold_memory: 80\npy_container_type: \"py_pytorch_onnx_container\"\n", "name":"wmlscoringpytorchonnx13-250"}}'


create cm wmlscoringtf21-250 --from-literal module=wmldeployment
patch cm wmlscoringtf21-250 -p '{"data": { "newrelic.ini" : "# ---------------------------------------------------------------------------\n\n#\n# This file configures the New Relic Python Agent.\n#\n# The path to the configuration file should be supplied to the function\n# newrelic.agent.initialize() when the agent is being initialized.\n#\n# The configuration file follows a structure similar to what you would\n# find for Microsoft Windows INI files. For further information on the\n# configuration file format see the Python ConfigParser documentation at:\n#\n#    http://docs.python.org/library/configparser.html\n#\n# For further discussion on the behaviour of the Python agent that can\n# be configured via this configuration file see:\n#\n#    http://newrelic.com/docs/python/python-agent-configuration\n#\n\n# ---------------------------------------------------------------------------\n\n# Here are the settings that are common to all environments.\n\n[newrelic]\n\n# You must specify the license key associated with your New\n# Relic account. This key binds the Python Agents data to your\n# account in the New Relic service.\nlicense_key = 78ab31635abad63c0ad9eb0f409ed909e642d66c\n\n# The application name. Set this to be the name of your\n# application as you would like it to show up in New Relic UI.\n# The UI will then auto-map instances of your application into a\n# entry on your home dashboard page.\napp_name = wml-os-rt-tensorflow2.1-fvt\n\n# When \"true\", the agent collects performance data about your\n# application and reports this data to the New Relic UI at\n# newrelic.com. This global switch is normally overridden for\n# each environment below.\nmonitor_mode = true\n\n# Sets the name of a file to log agent messages to. Useful for\n# debugging any issues with the agent. This is not set by\n# default as it is not known in advance what user your web\n# application processes will run as and where they have\n# permission to write to. Whatever you set this to you must\n# ensure that the permissions for the containing directory and\n# the file itself are correct, and that the user that your web\n# application runs as can write to the file. If not able to\n# write out a log file, it is also possible to say \"stderr\" and\n# output to standard error output. This would normally result in\n# output appearing in your web server log.\n#log_file = /tmp/newrelic-python-agent.log\n\n# Sets the level of detail of messages sent to the log file, if\n# a log file location has been provided. Possible values, in\n# increasing order of detail, are: \"critical\", \"error\", \"warning\",\n# \"info\" and \"debug\". When reporting any agent issues to New\n# Relic technical support, the most useful setting for the\n# support engineers is \"debug\". However, this can generate a lot\n# of information very quickly, so it is best not to keep the\n# agent at this level for longer than it takes to reproduce the\n# problem you are experiencing.\nlog_level = info\n\n# High Security Mode enforces certain security settings, and prevents\n# them from being overridden, so that no sensitive data is sent to New\n# Relic. Enabling High Security Mode means that request parameters are\n# not collected and SQL can not be sent to New Relic in its raw form.\n# To activate High Security Mode, it must be set to true in this\n# local .ini configuration file AND be set to true in the\n# server-side configuration in the New Relic user interface. For\n# details, see\n# https://docs.newrelic.com/docs/subscriptions/high-security\nhigh_security = false\n\n# The Python Agent will attempt to connect directly to the New\n# Relic service. If there is an intermediate firewall between\n# your host and the New Relic service that requires you to use a\n# HTTP proxy, then you should set both the \"proxy_host\" and\n# \"proxy_port\" settings to the required values for the HTTP\n# proxy. The \"proxy_user\" and \"proxy_pass\" settings should\n# additionally be set if proxy authentication is implemented by\n# the HTTP proxy. The \"proxy_scheme\" setting dictates what\n# protocol scheme is used in talking to the HTTP proxy. This\n# would normally always be set as \"http\" which will result in the\n# agent then using a SSL tunnel through the HTTP proxy for end to\n# end encryption.\n# proxy_scheme = http\n# proxy_host = hostname\n# proxy_port = 8080\n# proxy_user =\n# proxy_pass =\n\n# Capturing request parameters is off by default. To enable the\n# capturing of request parameters, first ensure that the setting\n# \"attributes.enabled\" is set to \"true\" (the default value), and\n# then add \"request.parameters.*\" to the \"attributes.include\"\n# setting. For details about attributes configuration, please\n# consult the documentation.\n# attributes.include = request.parameters.*\n\n# The transaction tracer captures deep information about slow\n# transactions and sends this to the UI on a periodic basis. The\n# transaction tracer is enabled by default. Set this to \"false\"\n# to turn it off.\ntransaction_tracer.enabled = true\n\n# Threshold in seconds for when to collect a transaction trace.\n# When the response time of a controller action exceeds this\n# threshold, a transaction trace will be recorded and sent to\n# the UI. Valid values are any positive float value, or (default)\n# \"apdex_f\", which will use the threshold for a dissatisfying\n# Apdex controller action - four times the Apdex T value.\ntransaction_tracer.transaction_threshold = apdex_f\n\n# When the transaction tracer is on, SQL statements can\n# optionally be recorded. The recorder has three modes, \"off\"\n# which sends no SQL, \"raw\" which sends the SQL statement in its\n# original form, and \"obfuscated\", which strips out numeric and\n# string literals.\ntransaction_tracer.record_sql = obfuscated\n\n# Threshold in seconds for when to collect stack trace for a SQL\n# call. In other words, when SQL statements exceed this\n# threshold, then capture and send to the UI the current stack\n# trace. This is helpful for pinpointing where long SQL calls\n# originate from in an application.\ntransaction_tracer.stack_trace_threshold = 0.5\n\n# Determines whether the agent will capture query plans for slow\n# SQL queries. Only supported in MySQL and PostgreSQL. Set this\n# to \"false\" to turn it off.\ntransaction_tracer.explain_enabled = true\n\n# Threshold for query execution time below which query plans\n# will not not be captured. Relevant only when \"explain_enabled\"\n# is true.\ntransaction_tracer.explain_threshold = 0.5\n\n# Space separated list of function or method names in form\n# module:function or module:class.function for which\n# additional function timing instrumentation will be added.\n# transaction_tracer.function_trace =\n\n# The error collector captures information about uncaught\n# exceptions or logged exceptions and sends them to UI for\n# viewing. The error collector is enabled by default. Set this\n# to \"false\" to turn it off.\nerror_collector.enabled = true\n\n# To stop specific errors from reporting to the UI, set this to\n# a space separated list of the Python exception type names to\n# ignore. The exception name should be of the form module:class.\n# error_collector.ignore_errors =\n\n# Browser monitoring is the Real User Monitoring feature of the UI.\n# For those Python web frameworks that are supported, this\n# setting enables the auto-insertion of the browser monitoring\n# JavaScript fragments.\nbrowser_monitoring.auto_instrument = true\n\n# A thread profiling session can be scheduled via the UI when\n# this option is enabled. The thread profiler will periodically\n# capture a snapshot of the call stack for each active thread in\n# the application to construct a statistically representative\n# call tree.\nthread_profiler.enabled = true\n\n# Your application deployments can be recorded through the\n# New Relic REST API. To use this feature provide your API key\n# below then use the `newrelic-admin record-deploy` command.\n# api_key =\n\n# ---------------------------------------------------------------------------\n\n#\n# The application environments. These are specific settings which\n# override the common environment settings. The settings related to a\n# specific environment will be used when the environment argument to the\n# newrelic.agent.initialize() function has been defined to be either\n# \"development\", \"test\", \"staging\" or \"production\".\n#\n\n[newrelic:development]\nmonitor_mode = false\n\n[newrelic:test]\nmonitor_mode = false\n\n[newrelic:staging]\napp_name = Python Application (Staging)\nmonitor_mode = true\n\n[newrelic:production]\nmonitor_mode = true\n\n# ---------------------------------------------------------------------------\n", "name":"wmlscoringtf21-250"}}'
patch cm wmlscoringtf21-250 -p '{"data": { "py_ml_scoring_container_configs.yml" : "flask_server_container_config:\n  app_ser_size: 1024\n\nscoring_container_config:\n  runtimes:\n    tensorflow: [\"2.1\"]\n  keras_to_tf_convert: False\n  threshold_memory: 80\npy_container_type: \"py_tensorflow_container\"\n", "name":"wmlscoringtf21-250"}}'


patch deployment  wmlrepository --patch '{"spec": {"template": {"spec": {"containers": [{"image": "{{.DockerRegistryPrefix}}/mlrepositoryservicehydra:v.0.1.1266.0.27","name": "wmlrepositoryservice","resources": {"limits": {"cpu": "2","memory": "3Gi"}}}]}}}}'

patch deployment  wmltraining --patch '{"spec": {"template": {"spec": {"containers": [{"name": "wmltrainingservice","image": "{{.DockerRegistryPrefix}}/wmltrainingservicehydra:v.0.1.2248.0.12"}]}}}}'

patch deployment  wml-etcd  --patch '{"spec": {"template": {"spec": {"containers": [{"name": "wml-etcd","image": "{{.DockerRegistryPrefix}}/etcd-ubi:v.v3.3.5.2"}]}}}}'

patch deployment  wml-os-envoy  --patch '{"spec": {"template": {"spec": {"containers": [{"name": "wml-os-envoy","image": "{{.DockerRegistryPrefix}}/wml-os-envoy:v.0.1.116.0.3"}]}}}}'

patch statefulset  wml-scoring-rt-utils  --patch '{"spec": {"template": {"spec": {"containers": [{"name": "agent-container","image": "{{.DockerRegistryPrefix}}/wml-os-runtime-agent:v.0.1.466.0.22"}]}}}}'

patch statefulset  wml-os-manager  --patch '{"spec": {"template": {"spec": {"containers": [{"name": "runtimemanagercontainer","image": "{{.DockerRegistryPrefix}}/wml-os-runtime-manager:v.0.1.729.0.12"}]}}}}'

patch deployment  wml-main  --patch '{"spec": {"template": {"spec": {"containers": [{"name": "wml-main","image": "{{.DockerRegistryPrefix}}/wml-main:v2.5.0_050221"}]}}}}'

